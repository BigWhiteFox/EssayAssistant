import gradio as gr
from gradio.components import Image, File, Slider
from moonshot import paper_analysis, upload_file_data
from divide import segmentation
from messages import fox_chat_chat, fox_say_read_paper, fox_say_read_paper_combine_with_analysis, fox_write_arxiv
from get_data_consensus import extract_data
from chroma import chroma_data, chroma_query, chroma_file_data, chroma_query_write
from get_data import run
import time
import webbrowser

# åœ¨æ¨¡å—çº§åˆ«å®šä¹‰å…¨å±€å˜é‡
divide_pth = None
page = 1

js = """
function createGradioAnimation() {
    var container = document.createElement('div');
    container.id = 'gradio-animation';
    container.style.fontSize = '2em';
    container.style.fontWeight = 'bold';
    container.style.textAlign = 'center';
    container.style.marginBottom = '20px';

    var text = 'Welcome to ç‹è¨€ä¹±è¯­! ğŸ˜º ';
    for (var i = 0; i < text.length; i++) {
        (function(i){
            setTimeout(function(){
                var letter = document.createElement('span');
                letter.style.opacity = '0';
                letter.style.transition = 'opacity 0.5s';
                letter.innerText = text[i];

                container.appendChild(letter);

                setTimeout(function() {
                    letter.style.opacity = '1';
                }, 50);
            }, i * 250);
        })(i);
    }

    var gradioContainer = document.querySelector('.gradio-container');
    gradioContainer.insertBefore(container, gradioContainer.firstChild);

    return 'Animation created';
}
"""


# ä»¥ä¸‹æ˜¯ç‹èŠé¡µé¢å‡½æ•°
def fox_chat(key, text, history, image, max_new_tokens, top_p, temperature):
    history.append((text, fox_chat_chat(key=key, message=text, image_path=image,
                                        temperature=temperature, top_p=top_p, max_tokens=max_new_tokens)))
    return "", history


# ä»¥ä¸‹æ˜¯ç‹è¯´é¡µé¢å‡½æ•°
def fox_say_file_analysis(key, file):
    if file is None:
        return "No file uploaded"
    response = paper_analysis(api_key=key, file=file)
    collected_messages = []
    for idx, chunk in enumerate(response):
        chunk_message = chunk.choices[0].delta
        if not chunk_message.content: continue
        collected_messages.append(chunk_message)  # save the message
        yield ''.join([m.content for m in collected_messages])


def fox_say_chat(key, message, message2, history, combine, combine2, max_new_tokens, top_p, temperature):
    # è¿™é‡Œæ˜¯éœ€è¦æœ‰å›¾åƒè¾“å…¥ï¼Œ
    if divide_pth is not None and (combine or combine2):
        # æ­¤æ—¶æœ‰å›¾åƒè¾“å…¥ï¼Œä½†åªéœ€è¦ç»“åˆå›¾ç‰‡ï¼Œä¸éœ€è¦ç»“åˆåˆ†æ
        if combine and not combine2:
            history.append((message, fox_say_read_paper(key=key,
                                                        message=message,
                                                        image_path=divide_pth[page - 1],
                                                        temperature=temperature,
                                                        top_p=top_p,
                                                        max_tokens=max_new_tokens)))
            return "", history
        # æ­¤æ—¶æœ‰å›¾åƒè¾“å…¥ï¼Œä½†åªéœ€è¦ç»“åˆåˆ†æï¼Œä¸éœ€è¦ç»“åˆå›¾ç‰‡
        elif combine2 and not combine:
            history.append((message, fox_say_read_paper_combine_with_analysis(key=key,
                                                                              message=message,
                                                                              analysis_input=message2,
                                                                              image_path=None,
                                                                              temperature=temperature,
                                                                              top_p=top_p,
                                                                              max_tokens=max_new_tokens)))
            return "", history
        # æ­¤æ—¶æœ‰å›¾åƒè¾“å…¥ï¼Œéœ€è¦ç»“åˆå›¾ç‰‡å’Œåˆ†æ
        else:
            history.append((message, fox_say_read_paper_combine_with_analysis(key=key,
                                                                              message=message,
                                                                              analysis_input=message2,
                                                                              image_path=divide_pth[page - 1],
                                                                              temperature=temperature,
                                                                              top_p=top_p,
                                                                              max_tokens=max_new_tokens
                                                                              )))
            return "", history
    # ä¸ç®¡æ€ä¹ˆæ ·ï¼Œè¿™æ˜¯æ— å›¾ï¼Œæ— éœ€ç»“åˆå›¾åƒå’Œåˆ†æçš„å›ç­”ã€‚å’Œæœ‰å›¾ä½†ä¸éœ€è¦ç»“åˆå›¾åƒå’Œåˆ†æçš„å›ç­”ã€‚
    else:
        history.append((message, fox_say_read_paper(key=key,
                                                    message=message,
                                                    image_path=None,
                                                    temperature=temperature,
                                                    top_p=top_p,
                                                    max_tokens=max_new_tokens)))
        return "", history, ""


def fox_say_image_show(file):
    global divide_pth, page
    page = 1
    divide_pth = segmentation(file)
    return divide_pth[0], f"å½“å‰ä¸ºç¬¬1/{len(divide_pth)}é¡µ"


def fox_say_image_switch1():
    global divide_pth, page
    if page == 1:
        return divide_pth[page - 1], f"å½“å‰ä¸ºç¬¬{page}/{len(divide_pth)}é¡µ"
    else:
        page -= 1
        return divide_pth[page - 1], f"å½“å‰ä¸ºç¬¬{page}/{len(divide_pth)}é¡µ"


def fox_say_image_switch2():
    global divide_pth, page
    if page == len(divide_pth):
        return divide_pth[page - 1], f"å½“å‰ä¸ºç¬¬{page}/{len(divide_pth)}é¡µ"
    else:
        page += 1
        return divide_pth[page - 1], f"å½“å‰ä¸ºç¬¬{page}/{len(divide_pth)}é¡µ"


# ä»¥ä¸‹æ˜¯ç‹æ‰¾é¡µé¢å‡½æ•°
def fox_find_data(key, text_input):
    relevance, reference = run(llm_key=key, text=text_input, n=2)
    consensus_data = extract_data(text_input, 1)
    chroma_data(1)
    chroma_data(2)
    chroma_data(3)
    return relevance, reference, consensus_data


def fox_find_chat(key, message, history):
    history.append((message, chroma_query(llm_key=key, query=message)))
    return "", history


# ä»¥ä¸‹æ˜¯ç‹å†™é¡µé¢å‡½æ•°
def fox_write(key, query, max_new_tokens, top_p, temperature):
    # åœ¨è¿™é‡Œå¤„ç†è¾“å…¥
    response = chroma_query_write(llm_key=key, query=query,
                                  max_tokens=max_new_tokens, top_p=top_p, temperature=temperature)
    collected_messages = []
    for idx, chunk in enumerate(response):
        chunk_message = chunk.choices[0].delta
        if not chunk_message.content: continue
        collected_messages.append(chunk_message)  # save the message
        yield ''.join([m.content for m in collected_messages])


def fox_write_extra(message):
    msg = fox_write_arxiv(message)
    # åˆå§‹åŒ–ä¸€ä¸ªæ ‡å¿—ï¼Œç”¨äºæŒ‡ç¤ºæ˜¯å¦å·²ç»é‡åˆ°éç©ºå†…å®¹
    started_output = False
    collected_messages = []
    for content in msg.content:
        # å¦‚æœå†…å®¹æ˜¯éç©ºçš„ï¼Œè®¾ç½®æ ‡å¿—ä¸ºTrueå¹¶æ‰“å°å†…å®¹
        if content.answer.strip():
            started_output = True
        if started_output:
            collected_messages.append(content.answer)
            yield ''.join([m for m in collected_messages])


def fox_write_upload(key, files):
    # è¿”å›ä¸Šä¼ æ–‡ä»¶çš„è·¯å¾„åˆ—è¡¨
    text = []
    for file in files:
        text.append(upload_file_data(api_key=key, file=file))
        time.sleep(3)

    # return [file.name for file in files]
    print(type(text))
    print(text)
    chroma_file_data(text)


# åˆ›å»º Gradio blocks ç•Œé¢
with gr.Blocks(theme='rawrsor1/Everforest', js=js) as demo:
    with gr.Tab("ç‹èŠ"):
        with gr.Row():
            with gr.Column():
                with gr.Accordion("Key", open=False):
                    llm_key = gr.Textbox(label="è¯·è¾“å…¥å¤§æ¨¡å‹API Key", placeholder="è¯·è¾“å…¥ä½ çš„API Key",
                                         value="bbbd0deb2e83869a810a3aa32d866b36.z8W6AkgbgewipUae")
                    moonshot_key = gr.Textbox(label="è¯·è¾“å…¥ä½ çš„æœˆä¹‹æš—é¢API Key", placeholder="è¯·è¾“å…¥ä½ çš„API Key",
                                              value="sk-by3QJVIDS2QakUYRVNe196GgP64IYSKx0BoCBlpN9ze171e0")
                image_upload = Image(type="filepath", label="ä½ æœ‰ä»€ä¹ˆæƒ³ç»™å¤§ç‹ç‹¸çœ‹çš„å—ï¼Ÿ")
                with gr.Accordion("Parameters", open=False):
                    with gr.Column():
                        max_new_tokens1 = Slider(minimum=256, maximum=4096, value=1024, step=1, label='Max new tokens')
                        top_p1 = Slider(minimum=0.01, maximum=1, value=0.7, step=0.01, label='Top_p')
                        temperature1 = Slider(minimum=0.01, maximum=1, value=0.8, step=0.01, label='Temperature')
            with gr.Column():
                chat_box2 = gr.Chatbot(label="å—¨~~å¤§ç‹ç‹¸ğŸ¦Šè¶…å¼€å¿ƒé‡è§ä½ ï¼ä½ æœ€è¿‘æœ‰ä»€ä¹ˆå¥½ç©çš„äº‹æƒ…æƒ³å’Œæˆ‘åˆ†äº«å—ï¼ŸğŸŒŸ ")
                chat_box2.like(None)
                with gr.Row():
                    # åˆ›å»ºä¸€ä¸ªTextboxç»„ä»¶ä½œä¸ºè¾“å…¥æ 
                    fox_chat_chat_input = gr.Textbox(label="", placeholder="è¯·è¾“å…¥æ‚¨çš„æ¶ˆæ¯å¹¶æŒ‰å›è½¦â†©")
                clear2 = gr.ClearButton([fox_chat_chat_input, chat_box2, image_upload])
        fox_chat_chat_input.submit(fn=fox_chat, inputs=[llm_key, fox_chat_chat_input, chat_box2,
                                                        image_upload, max_new_tokens1, top_p1, temperature1],
                                   outputs=[fox_chat_chat_input, chat_box2])

    with gr.Tab("ç‹è¯´"):
        with gr.Row():
            # å·¦ä¾§ç•Œé¢ï¼š PDFå±•ç¤ºã€ä¸Šä¼ ã€æ˜¯å¦ç»“åˆã€é¡µç æ‰«æã€å‚æ•°è®¾ç½®
            with gr.Column(scale=15):
                # PDFé¡µé¢å±•ç¤ºç»„ä»¶
                pdf_image_display = Image(type="filepath", label="è®ºæ–‡å±•ç¤º")

                with gr.Row():
                    # PDFæ–‡ä»¶ä¸Šä¼ ç»„ä»¶
                    pdf_upload = File(label="ä¸Šä¼ PDF")
                    switch_button_1 = gr.Button(value="â¬…ï¸", min_width=1, size="sm")
                    page_num = gr.Textbox(label="")
                    switch_button_2 = gr.Button(value="â¡ï¸", min_width=1, size="sm")

                with gr.Row():
                    fox_say_paper_button = gr.Button(value="è®©å¤§ç‹ç‹¸æ¥åˆ†æä¸€ä¸‹ğŸ•µï¸â€â™‚ï¸")
                    checkbox = gr.Checkbox(label="ç»“åˆæ­¤é¡µå±•ç¤ºå›ç­”")
                    checkbox2 = gr.Checkbox(label="ç»“åˆè®ºæ–‡è§£è¯»å›ç­”")
                with gr.Accordion("Parameters", open=False):
                    with gr.Column():
                        max_new_tokens2 = Slider(minimum=256, maximum=4096, value=1024, step=1, label='Max new tokens')
                        top_p2 = Slider(minimum=0.01, maximum=1, value=0.7, step=0.01, label='Top_p')
                        temperature2 = Slider(minimum=0.01, maximum=1, value=0.8, step=0.01, label='Temperature')
            # å³ä¾§ç•Œé¢ï¼š è§£è¯»æ¡†ã€èŠå¤©æ¡†ã€æäº¤æŒ‰é’®ã€æ¸…ç©ºæŒ‰é’®
            with gr.Column(scale=10):
                pdf_text_display = gr.Textbox(label="è®ºæ–‡è§£è¯»", lines=20, max_lines=20)

                # åˆ›å»ºä¸€ä¸ªChatbotç»„ä»¶ä½œä¸ºèŠå¤©æ¡†
                chat_box = gr.Chatbot(label="What does the ğŸ¦Š say?")
                chat_box.like(None)

                with gr.Row():
                    # åˆ›å»ºä¸€ä¸ªTextboxç»„ä»¶ä½œä¸ºè¾“å…¥æ 
                    fox_say_chat_input = gr.Textbox(label="", placeholder="è¯·è¾“å…¥æ‚¨çš„æ¶ˆæ¯å¹¶æŒ‰å›è½¦â†©")
                clear = gr.ClearButton([fox_say_chat_input, chat_box])

            # å·¦ä¾§ç•Œé¢åŠŸèƒ½é“¾æ¥
            fox_say_paper_button.click(fn=fox_say_file_analysis,
                                       inputs=[moonshot_key, pdf_upload], outputs=pdf_text_display)
            pdf_upload.upload(fn=fox_say_image_show, inputs=pdf_upload, outputs=[pdf_image_display, page_num])
            switch_button_1.click(fn=fox_say_image_switch1, inputs=None, outputs=[pdf_image_display, page_num])
            switch_button_2.click(fn=fox_say_image_switch2, inputs=None, outputs=[pdf_image_display, page_num])
            # å³ä¾§ç•Œé¢åŠŸèƒ½é“¾æ¥
            fox_say_chat_input.submit(fn=fox_say_chat, inputs=[llm_key, fox_say_chat_input, pdf_text_display,
                                                               chat_box, checkbox, checkbox2, max_new_tokens2,
                                                               top_p2, temperature2],
                                      outputs=[fox_say_chat_input, chat_box])

    with gr.Tab("ç‹æ‰¾"):
        with gr.Row():
            with gr.Column():
                keyword_search = gr.Textbox(label="è¾“å…¥ä½ æƒ³æœç´¢çš„å…³é”®è¯")
                baidu_relevance = gr.DataFrame(label="ç™¾åº¦å­¦æœ¯ç›¸å…³åºåˆ—", height=420)
                baidu_reference = gr.DataFrame(label="ç™¾åº¦å­¦æœ¯å¼•ç”¨åºåˆ—", height=420)

            with gr.Column():
                consensus = gr.DataFrame(label="ConsensusSJRä¸€äºŒåŒºåºåˆ—", height=420)
                paper_find_chat = gr.Chatbot(label="å’Œå¤§ç‹ç‹¸èŠèŠä½ æƒ³æ‰¾çš„è®ºæ–‡")
                paper_find_chat.like(None)
                with gr.Row():
                    # åˆ›å»ºä¸€ä¸ªTextboxç»„ä»¶ä½œä¸ºè¾“å…¥æ 
                    fox_find_chat_input = gr.Textbox(label="", placeholder="è¯·è¾“å…¥æ‚¨çš„æ¶ˆæ¯å¹¶æŒ‰å›è½¦â†©")
                clear3 = gr.ClearButton([fox_find_chat_input, paper_find_chat,
                                         keyword_search, baidu_relevance, consensus])
        # ç•Œé¢åŠŸèƒ½é“¾æ¥
        keyword_search.submit(fn=fox_find_data, inputs=[llm_key, keyword_search],
                              outputs=[baidu_relevance, baidu_reference, consensus])
        # å°†å¤„ç†å‡½æ•°ç»‘å®šåˆ°submit_buttonç»„ä»¶
        fox_find_chat_input.submit(fn=fox_find_chat, inputs=[llm_key, fox_find_chat_input, paper_find_chat],
                                   outputs=[fox_find_chat_input, paper_find_chat])

    with gr.Tab("ç‹å†™"):
        with gr.Row():
            with gr.Column(scale=1):
                fox_write_input = gr.Textbox(label="ä½ æƒ³è®©å¤§ç‹ç‹¸å†™ä»€ä¹ˆæ ·çš„ç»¼è¿°ğŸ”¬ï¼Ÿ", placeholder="è¯·è¾“å…¥æ‚¨çš„æ¶ˆæ¯å¹¶æŒ‰å›è½¦â†©")
                upload_file = File(label="ä¸Šä¼ ä½ æƒ³è¦ä¸€èµ·åˆ†æçš„è®ºæ–‡ğŸ‘€", file_count="multiple")
                upload_file_button = gr.Button(value="ä¸Šä¼ æ–‡ä»¶")
                # clear4 = gr.ClearButton([fox_write_input, paper_summary_chat, upload_file])
                with gr.Accordion("Parameters", open=False):
                    with gr.Column():
                        max_new_tokens3 = Slider(minimum=2048, maximum=8192, value=4096, step=1, label='Max new tokens')
                        top_p3 = Slider(minimum=0.01, maximum=1, value=0.7, step=0.01, label='Top_p')
                        temperature3 = Slider(minimum=0.01, maximum=1, value=0.8, step=0.01, label='Temperature')
            with gr.Column(scale=5):
                with gr.Tab("Vector Database"):
                    paper_summary_chat = gr.Textbox(label="æ¥çœ‹çœ‹å¤§ç‹ç‹¸ä»æœ¬åœ°çŸ¥è¯†åº“æ‰¾æ•°æ®å†™çš„ç»¼è¿°ï¼Œå†™çš„ä¸å¥½è¿˜è¯·è§è°…ã€‚ğŸ˜£",
                                                    lines=20, max_lines=20, show_copy_button=True)
                with gr.Tab("Arxiv"):
                    paper_arxiv_chat = gr.Textbox(label="æ¥çœ‹çœ‹å¤§ç‹ç‹¸ä»arxivæ‰¾æ•°æ®å†™çš„ç»¼è¿°ï¼Œå†™çš„ä¸å¥½è¿˜è¯·è§è°…ã€‚ğŸ˜£",
                                                  lines=20, max_lines=20, show_copy_button=True)
        upload_file_button.click(fn=fox_write_upload, inputs=[moonshot_key, upload_file], outputs=None)
        fox_write_input.submit(fn=fox_write, inputs=[llm_key, fox_write_input, max_new_tokens3, top_p3, temperature3],
                               outputs=[paper_summary_chat])
        fox_write_input.submit(fn=fox_write_extra, inputs=fox_write_input, outputs=paper_arxiv_chat)

# å¯åŠ¨ç•Œé¢
webbrowser.open("http://localhost:7888")
demo.queue().launch(server_name="0.0.0.0", server_port=7888, share=False)
